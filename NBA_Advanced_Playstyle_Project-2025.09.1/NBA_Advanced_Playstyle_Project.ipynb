{"cells": [{"cell_type": "markdown", "id": "0f6b5630", "metadata": {}, "source": ["# üèÄ How Did NBA Player Playstyle Change Over the Years?\n", "**Date:** 2025-09-14\n", "\n", "**Authors:** <YOUR NAME(S)>\n", "\n", "In this notebook we analyze how NBA player playstyle evolved using advanced player statistics. We focus on usage rate (USG%), shot efficiency (TS%, eFG%), playmaking and rebounding shares, and impact metrics (BPM, VORP). We combine EDA (time trends & position differences), unsupervised clustering of playstyles, and a small supervised task."]}, {"cell_type": "markdown", "id": "dbff4f44", "metadata": {}, "source": ["## 1. Load Data\n", "We start from a precompiled table of **advanced per-season player stats** (one row per player-season)."]}, {"cell_type": "code", "execution_count": null, "id": "587fd5c9", "metadata": {}, "outputs": [], "source": ["import pandas as pd, numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "PATH = 'Advanced.csv'  # update if needed\n", "df = pd.read_csv(PATH)\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "id": "f55d9387-484c-4ab0-9505-02081e3971ae", "metadata": {}, "outputs": [], "source": ["# First, import pandas and create or load your DataFrame\n", "import pandas as pd\n", "\n", "# Option 1: Load data from a file\n", "# df = pd.read_csv('your_data_file.csv')  # Uncomment and modify this line to load your data\n", "\n", "# Option 2: Create sample data for demonstration\n", "# Creating a sample DataFrame with the required columns\n", "df = pd.DataFrame({\n", "    'season': [1985, 1990, 1995, 2000, 2005],\n", "    'player': ['Player1', 'Player2', 'Player3', 'Player4', 'Player5'],\n", "    'player_id': [1, 2, 3, 4, 5],\n", "    'age': [25, 27, 29, 24, 26],\n", "    'team': ['TeamA', 'TeamB', 'TeamC', 'TeamD', 'TeamE'],\n", "    'pos': ['G', 'F', 'C', 'G', 'F'],\n", "    'g': [80, 75, 82, 70, 78],\n", "    'gs': [70, 65, 80, 60, 75],\n", "    'mp': [2500, 2300, 2800, 1800, 2600],\n", "    'ts_percent': [0.55, 0.58, 0.52, 0.56, 0.59],\n", "    'efg_percent': [0.51, 0.53, 0.48, 0.52, 0.54],\n", "    'x3p_ar': [0.3, 0.35, 0.25, 0.4, 0.38],\n", "    'f_tr': [0.2, 0.25, 0.3, 0.22, 0.28],\n", "    'orb_percent': [5, 4, 8, 3, 6],\n", "    'drb_percent': [12, 15, 20, 10, 14],\n", "    'trb_percent': [8, 10, 15, 7, 9],\n", "    'ast_percent': [15, 12, 8, 20, 10],\n", "    'stl_percent': [2, 1.5, 1, 2.5, 1.8],\n", "    'blk_percent': [1, 2, 4, 0.5, 1.5],\n", "    'tov_percent': [10, 8, 12, 9, 11],\n", "    'usg_percent': [25, 22, 20, 28, 24],\n", "    'obpm': [2.5, 1.8, 0.5, 3.0, 2.0],\n", "    'dbpm': [1.0, 1.5, 3.0, 0.0, 1.2],\n", "    'bpm': [3.5, 3.3, 3.5, 3.0, 3.2],\n", "    'vorp': [4.0, 3.8, 3.5, 3.2, 3.7]\n", "})\n", "\n", "# Basic filtering\n", "df = df.copy()\n", "df = df[df['season'] >= 1990]\n", "df = df[df['mp'].fillna(0) >= 300]  # keep players with >=300 minutes in a season\n", "\n", "core_feats = ['ts_percent','efg_percent','x3p_ar','f_tr','orb_percent','drb_percent','trb_percent',\n", "              'ast_percent','stl_percent','blk_percent','tov_percent','usg_percent','obpm','dbpm','bpm','vorp']\n", "\n", "basic_cols = ['season','player','player_id','age','team','pos','g','gs','mp']\n", "\n", "df_core = df[basic_cols + core_feats].dropna()\n", "df_core.head()"]}, {"cell_type": "markdown", "id": "4244eda6", "metadata": {}, "source": ["### Quick data check"]}, {"cell_type": "code", "execution_count": null, "id": "d8b12764", "metadata": {}, "outputs": [], "source": ["df.shape, df.isnull().sum().sort_values(ascending=False).head(10)"]}, {"cell_type": "markdown", "id": "7da65651", "metadata": {}, "source": ["## 2. Cleaning & Preparation\n", "- Keep seasons in a reasonable window (e.g., from 1990 onward) to match modern era.\n", "- Remove rows with too few minutes (`mp`) to reduce noise.\n", "- Select core features for analysis."]}, {"cell_type": "code", "execution_count": null, "id": "b8356c80", "metadata": {}, "outputs": [], "source": ["# Basic filtering\n", "df = df.copy()\n", "df = df[df['season'] >= 1990]\n", "df = df[df['mp'].fillna(0) >= 300]  # keep players with >=300 minutes in a season\n", "\n", "core_feats = ['ts_percent','efg_percent','x3p_ar','f_tr','orb_percent','drb_percent','trb_percent',\n", "              'ast_percent','stl_percent','blk_percent','tov_percent','usg_percent','obpm','dbpm','bpm','vorp']\n", "\n", "basic_cols = ['season','player','player_id','age','team','pos','g','gs','mp']\n", "\n", "df_core = df[basic_cols + core_feats].dropna()\n", "df_core.head()"]}, {"cell_type": "markdown", "id": "6f265d46", "metadata": {}, "source": ["## 3. EDA: Time Trends\n", "We examine how key indicators evolved across seasons.\n", "- **USG%** (usage) ‚Äì offensive load trend.\n", "- **TS% / eFG%** ‚Äì shooting efficiency.\n", "- **AST% / TRB%** ‚Äì playmaking / rebounding shares."]}, {"cell_type": "code", "execution_count": null, "id": "2461d959", "metadata": {}, "outputs": [], "source": ["season_agg = df_core.groupby('season').agg({\n", "    'usg_percent':'mean', 'ts_percent':'mean', 'efg_percent':'mean',\n", "    'ast_percent':'mean', 'trb_percent':'mean'\n", "}).reset_index()\n", "season_agg.head()"]}, {"cell_type": "code", "execution_count": null, "id": "f62403d9", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['usg_percent'])\n", "plt.xlabel('Season'); plt.ylabel('USG% (mean)')\n", "plt.title('Usage Rate (USG%) by Season')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "d69aec22-e3cf-4327-a33f-8657e397a1cf", "metadata": {}, "outputs": [], "source": ["# Import matplotlib.pyplot library first\n", "import matplotlib.pyplot as plt\n", "\n", "# Now the plotting code will work\n", "plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['usg_percent'])\n", "plt.xlabel('Season'); plt.ylabel('USG% (mean)')\n", "plt.title('Usage Rate (USG%) by Season')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "fcac6690", "metadata": {}, "source": ["> **Interpretation:** A rising USG% suggests more concentrated offensive load on primary creators; a flat/decline suggests spreading touches."]}, {"cell_type": "code", "execution_count": null, "id": "6b2b7073", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['ts_percent'])\n", "plt.xlabel('Season'); plt.ylabel('TS% (mean)')\n", "plt.title('True Shooting% by Season')\n", "plt.show()\n", "\n", "plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['efg_percent'])\n", "plt.xlabel('Season'); plt.ylabel('eFG% (mean)')\n", "plt.title('eFG% by Season')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "b648c089", "metadata": {}, "source": ["> **Interpretation:** Increases in TS%/eFG% align with modern spacing and 3-point emphasis."]}, {"cell_type": "code", "execution_count": null, "id": "40bca2b4", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['ast_percent'])\n", "plt.xlabel('Season'); plt.ylabel('AST% (mean)')\n", "plt.title('Assist% by Season')\n", "plt.show()\n", "\n", "plt.figure(figsize=(10,5))\n", "plt.plot(season_agg['season'], season_agg['trb_percent'])\n", "plt.xlabel('Season'); plt.ylabel('TRB% (mean)')\n", "plt.title('Rebound% by Season')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "954107e8", "metadata": {}, "source": ["> **Interpretation:** Changes in AST% may reflect more ball movement/pick-and-roll reliance; TRB% can shift with pace and shot profile."]}, {"cell_type": "markdown", "id": "3f541a19", "metadata": {}, "source": ["## 4. EDA: Position Differences\n", "We compare positions (PG/SG/SF/PF/C) across eras. For compactness, we collapse detailed labels if needed."]}, {"cell_type": "code", "execution_count": null, "id": "b6a4e327", "metadata": {}, "outputs": [], "source": ["def canonical_pos(p):\n", "    if pd.isna(p):\n", "        return np.nan\n", "    p = str(p).upper()\n", "    for k in ['PG','SG','SF','PF','C']:\n", "        if k in p:\n", "            return k\n", "    return p\n", "\n", "df_core['pos_simple'] = df_core['pos'].apply(canonical_pos)\n", "era = pd.cut(df_core['season'], bins=[1989,1999,2009,2019,2100], labels=['1990s','2000s','2010s','2020s'])\n", "era_pos = df_core.assign(era=era)\n", "\n", "pos_agg = era_pos.groupby(['era','pos_simple']).agg({\n", "    'usg_percent':'mean','ts_percent':'mean','ast_percent':'mean','trb_percent':'mean'\n", "}).reset_index()\n", "pos_agg.head()"]}, {"cell_type": "code", "execution_count": null, "id": "02a33283", "metadata": {}, "outputs": [], "source": ["for m in ['usg_percent','ts_percent','ast_percent','trb_percent']:\n", "    pivot = pos_agg.pivot(index='pos_simple', columns='era', values=m)\n", "    pivot = pivot.loc[['PG','SG','SF','PF','C']].dropna(how='all')\n", "    pivot.plot(kind='bar', figsize=(10,5))\n", "    plt.title(f'{m} by Position and Era')\n", "    plt.ylabel(m)\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "bbfe49dc-aa4d-4797-a297-33880e9deaa4", "metadata": {}, "outputs": [], "source": ["for m in ['usg_percent','ts_percent','ast_percent','trb_percent']:\n", "    pivot = pos_agg.pivot(index='pos_simple', columns='era', values=m)\n", "    \n", "    # Check which positions actually exist in the index\n", "    available_positions = [pos for pos in ['PG','SG','SF','PF','C'] if pos in pivot.index]\n", "    \n", "    # Only select positions that exist in the pivot table\n", "    if available_positions:  # Make sure there's at least one position available\n", "        pivot = pivot.loc[available_positions].dropna(how='all')\n", "        pivot.plot(kind='bar', figsize=(10,5))\n", "        plt.title(f'{m} by Position and Era')\n", "        plt.ylabel(m)\n", "        plt.show()\n", "    else:\n", "        print(f\"No matching positions found for {m}. Available positions: {pivot.index.tolist()}\")"]}, {"cell_type": "markdown", "id": "81c11b50", "metadata": {}, "source": ["> **Interpretation:** Expect rising TS% across positions in modern eras, PGs with higher AST%, wings with higher 3P profile, bigs evolving to higher spacing (x3p_ar)."]}, {"cell_type": "markdown", "id": "952568c7", "metadata": {}, "source": ["## 5. Unsupervised: Clustering Player-Seasons by Playstyle\n", "We cluster player-seasons using a subset of features, then visualize with PCA."]}, {"cell_type": "code", "execution_count": null, "id": "e16f62c4", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "from sklearn.decomposition import PCA\n", "from sklearn.cluster import KMeans\n", "\n", "features = ['ts_percent','efg_percent','x3p_ar','f_tr','ast_percent','trb_percent','tov_percent','usg_percent']\n", "X = df_core[features].astype(float)\n", "X_scaled = StandardScaler().fit_transform(X)\n", "\n", "pca = PCA(n_components=2)\n", "X_pca = pca.fit_transform(X_scaled)\n", "\n", "kmeans = KMeans(n_clusters=4, random_state=42)\n", "labels = kmeans.fit_predict(X_scaled)\n", "\n", "plt.figure(figsize=(8,6))\n", "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels)\n", "plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title('PCA of Playstyle (colored by KMeans clusters)')\n", "plt.show()\n", "\n", "df_core['cluster'] = labels\n", "df_core[['season','player','pos','pos_simple','cluster']].head()"]}, {"cell_type": "markdown", "id": "97b328ad", "metadata": {}, "source": ["> **Interpretation:** Clusters often align with guards/wings/bigs and shooting profiles (3P oriented vs rim/FT oriented)."]}, {"cell_type": "markdown", "id": "89d251ec", "metadata": {}, "source": ["## 6. Supervised: Predict \"Star\" Status from Playstyle\n", "We define **Star = top 20% VORP** across the dataset and train simple models to predict this class from playstyle features."]}, {"cell_type": "code", "execution_count": null, "id": "de1d40f4", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.inspection import permutation_importance\n", "\n", "thr = df_core['vorp'].quantile(0.80)\n", "df_core['star'] = (df_core['vorp'] >= thr).astype(int)\n", "\n", "X = df_core[features]\n", "y = df_core['star']\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n", "\n", "# Logistic Regression baseline\n", "logreg = LogisticRegression(max_iter=1000)\n", "logreg.fit(X_train, y_train)\n", "y_pred = logreg.predict(X_test)\n", "print('Logistic Regression:')\n", "print(classification_report(y_test, y_pred))\n", "\n", "# Random Forest\n", "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n", "rf.fit(X_train, y_train)\n", "y_pred_rf = rf.predict(X_test)\n", "print('Random Forest:')\n", "print(classification_report(y_test, y_pred_rf))\n", "\n", "# Permutation importance (RF)\n", "r = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n", "imp = pd.Series(r.importances_mean, index=X.columns).sort_values(ascending=False)\n", "imp.plot(kind='bar', figsize=(10,5))\n", "plt.title('Permutation Importance (Random Forest)')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "9a5a0ca7-99ff-4ffa-8dc1-9b2f26401243", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.inspection import permutation_importance\n", "\n", "# Adjust the threshold to ensure more balanced classes\n", "# You might need to experiment with different values\n", "thr = df_core['vorp'].quantile(0.80)\n", "df_core['star'] = (df_core['vorp'] >= thr).astype(int)\n", "\n", "# Check class distribution before splitting\n", "print(\"Class distribution:\", df_core['star'].value_counts())\n", "\n", "X = df_core[features]\n", "y = df_core['star']\n", "\n", "# Remove stratify if the minority class is too small\n", "# Option 1: Don't use stratification\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "\n", "# Option 2 (alternative): Adjust threshold to get more balanced classes\n", "# thr = df_core['vorp'].quantile(0.75)  # Try a different threshold\n", "# df_core['star'] = (df_core['vorp'] >= thr).astype(int)\n", "# X = df_core[features]\n", "# y = df_core['star']\n", "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n", "\n", "# Logistic Regression baseline\n", "logreg = LogisticRegression(max_iter=1000)\n", "logreg.fit(X_train, y_train)\n", "y_pred = logreg.predict(X_test)\n", "print('Logistic Regression:')\n", "print(classification_report(y_test, y_pred))\n", "\n", "# Random Forest\n", "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n", "rf.fit(X_train, y_train)\n", "y_pred_rf = rf.predict(X_test)\n", "print('Random Forest:')\n", "print(classification_report(y_test, y_pred_rf))\n", "\n", "# Permutation importance (RF)\n", "r = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n", "imp = pd.Series(r.importances_mean, index=X.columns).sort_values(ascending=False)\n", "imp.plot(kind='bar', figsize=(10,5))\n", "plt.title('Permutation Importance (Random Forest)')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "e1b3608a", "metadata": {}, "source": ["> **Interpretation:** Feature importance helps explain which aspects of playstyle (usage, efficiency, playmaking, etc.) best distinguish star-level impact."]}, {"cell_type": "markdown", "id": "21dc562e", "metadata": {}, "source": ["## 7. Conclusion & Next Steps\n", "- **Trends**: summarize observed shifts (e.g., rising TS%/eFG%, changes in USG%).\n", "- **Positions**: how roles evolved across eras.\n", "- **Clustering**: distinct playstyle groups emerged.\n", "- **Prediction**: which features best predict star status.\n", "\n", "**Next**: add team-level context, era-aware targets (percentiles per season), or more sophisticated explainability (SHAP)."]}, {"cell_type": "code", "execution_count": null, "id": "40ba0de7-3032-4264-9e6f-572c2171078e", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "4a9c451b-8c53-4463-b2bd-a5bea9cfbffc", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "a1786a5c-d0fc-4be9-a1d1-05eac106e212", "metadata": {}, "outputs": [], "source": []}], "metadata": {"language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}